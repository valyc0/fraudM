input {
  file {
    path => "/data/*.csv"
    start_position => "beginning"
    sincedb_path => "/dev/null"
    mode => "read"
    file_completed_action => "log"
    file_completed_log_path => "/data/completed_files.log"
    sincedb_clean_after => "2 days"
    codec => plain {
      charset => "UTF-8"
    }
    discover_interval => "5"
  }
}

filter {
  csv {
    separator => ","
    skip_header => true
    columns => ["tenant", "val_euro", "duration", "economicUnitValue", "other_party_country", 
               "routing_dest", "service_type__desc", "op35", "carrier_in", "carrier_out", 
               "selling_dest", "raw_caller_number", "raw_called_number", "paese_destinazione", 
               "event_timestamp", "xdrid"]
    skip_empty_columns => true
  }

  # Set default empty value for op35 if missing
  if ![op35] {
    mutate {
      add_field => { "op35" => "" }
    }
  }

  # Convert numeric fields
  mutate {
    convert => {
      "val_euro" => "float"
      "duration" => "integer"
      "economicUnitValue" => "float"
    }
  }

  # Convert event_timestamp to proper ISO-8601 format
  date {
    match => [ "event_timestamp", "ISO8601" ]
    target => "event_timestamp"
    timezone => "Europe/Rome"
  }

  # Add metadata fields
  mutate {
    add_field => { 
      "event_type" => "call_record"
      "kafka_timestamp" => "%{@timestamp}"
    }
  }

  # Clean up unwanted fields
  mutate {
    remove_field => ["path", "host", "@version", "message", "@metadata"]
  }
}

output {
  kafka {
    bootstrap_servers => "kafka:29092"
    topic_id => "call-data-raw"
    codec => json
    message_key => "%{xdrid}"
    value_serializer => "org.apache.kafka.common.serialization.StringSerializer"
  }
}